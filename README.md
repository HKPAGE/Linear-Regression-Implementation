<h1>Simple and Multiple Linear Regression Implementation and Comparison</h1>
<p>This project is an introduction to the concepts of Simple and Multiple Linear Regression. I implemented both models from scratch in Python using NumPy for all calculations, without relying on any machine learning libraries such as scikit-learn, PyTorch, or Keras. Through this project, I gained a deep understanding of the mathematics behind linear regression, which is essential for critically evaluating models in real-world scenarios.</p>

<p>Additionally, I learned LaTeX in order to create all the mathematical visuals myself and used Matplotlib (Pyplot) to visualize model performance, including predictions, residuals, and feature contributions. This project strengthened both my mathematical and visualization skills and gave me practical experience in connecting mathematical theory to actual Python implementations.</p>

<p>The project is broken up into two Jupyter notebooks, one being on simple regression, with the other on multiple linear regression. I used this approach because I thought it would be more organized than having everything in one, longer notebook. I also created a very short python script that contained functions to calculate basic $R^2$ and $RMSE$ values. This script was not used in the first notebook, only in the second one when comparing the results of the individual features to the multi-feature model. Requirements can be found in requirements.txt, and you can follow along through the notebooks in order.<p>
